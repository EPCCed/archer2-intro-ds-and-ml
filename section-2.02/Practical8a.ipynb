{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c37f142e-0ba5-45ee-896b-3e2ef32b6f60",
   "metadata": {},
   "source": [
    "# __Neural Networks in Scikit-Learn and NumPy (Part A)__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cbb9e6-1c90-486f-bb50-30bd809862a9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Scikit-Learn is not intended for use in large-scale Deep Learning projects...</div>\n",
    "\n",
    "...It does, however, offer the required functionality to build simple DL models, such as the Multi-layer Perceptron (MLP), which we will use here. (An MLP has every node in one layer connected to every node in the next layer: it's **fully-connected**.)\n",
    "Later we take this a step further with NumPy, in which more control over the architecture of the neural network is available, and training can become more complex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f2d4b-df9d-4ded-bdab-c7ff217394e7",
   "metadata": {},
   "source": [
    "We start with some general imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85b7ed5-5bf0-4da5-a9a4-2433000ed4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b23bac-bcfc-43f7-93c1-a6a052ac2681",
   "metadata": {},
   "source": [
    "And then we generate some tricky data. We're using the function `make_moons` to generate some synthetic data that would be harder to classify with a simple classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c06560c-36ec-48a6-867b-afde9fb78a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples = 500, noise = 0.2, random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cdbc35-e432-452e-b38a-127867ff5815",
   "metadata": {},
   "source": [
    "Split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1de2bd-e666-47f8-a509-433c2a550187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert code here to split the data into 80:20 training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41af197-1c5d-4653-a415-ad5f6ef6b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise the training data\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X_train[:,0], X_train[:,1], c = y_train, edgecolors='k', cmap = cm_bright)\n",
    "plt.title('Training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2d15ff-4097-49d6-88c3-d8601020cad3",
   "metadata": {},
   "source": [
    "We will now attempt to build a neural network classifier that can accurately predict the classes data in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0803187-5d00-4543-a1c4-10485499b7ef",
   "metadata": {},
   "source": [
    "Import the sklearn Classifier based on the MLP algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e55b98e-32cd-4910-96d3-46592b1bc0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45294e31-0e47-4906-a649-2d29180d600a",
   "metadata": {},
   "source": [
    "We now want to train a neural network model, to classify red and blue points based on their coordinates, with the MLPClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b900e7be-fdce-4c6b-baa2-e424dd2f8dbc",
   "metadata": {},
   "source": [
    "A lot of the setup of the neural network is taken care of for us, and some things are fixed:\n",
    "- there is no activation function for the output layer\n",
    "- cross-entropy is used as the loss function\n",
    "- we cannot use different activation functions or weight initialisers for different layers\n",
    "\n",
    "Here we use an [L-BFGS](https://en.wikipedia.org/wiki/Limited-memory_BFGS) solver. This is a little bit more complicated that using gradient descent, but the principle is similar: it's an interative procedure based on gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc639e1-577a-4796-a1c4-fc787c8dbd28",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(5,2), random_state=1, alpha=1e-5)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388d4f23-e20b-4b90-ae57-ac54b7cb976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c10cc40-555e-414f-94a8-443a037271f1",
   "metadata": {},
   "source": [
    "Now check the score (the mean accuracy of `self.predict(X)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22624f61-a3a0-4177-b5f3-827424a57319",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feef651-2a7c-47d7-8273-b22c02332356",
   "metadata": {},
   "source": [
    "In the cells below, get some details about the predictions the model can make.\n",
    "\n",
    "Hint: type \"clf.\" then double-hit <kbd>tab</kbd>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99309062-f212-44de-98d1-b9967b3dc037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert code (one line) to predict the classes for the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd39db9a-2a0c-4c37-a727-c0784d2dc7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert code (one line) to list the classification probabilities for the test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3211524-4fd9-49eb-bc67-f0116158e52c",
   "metadata": {},
   "source": [
    "__Have a play:__\n",
    "- How does adjusting `alpha` affect the score?\n",
    "- How does changing `hidden_layer_sizes` affect the score, or the training time? Note: we can use hidden layers as the total number of layer minus 2 (the input and output layers). `hidden_layer_sizes=(5, 2)` means there will be two hidden layers, the first with 5 units and the second with 2 units. Try one to three layers with 1 to 10 units per layer. How does this change things? Also look out for convergence warnings as the number of parameters increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c0b9ba-4a89-4ebb-8285-65b55ea99f07",
   "metadata": {},
   "source": [
    "__Visualise model boundaries__ _Note: this is not a prediction, but shows how the feature space is divided into classes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5108b074-ed29-46da-aa54-924771357285",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X_train[:,0], X_train[:,1], c = y_train.ravel(), edgecolors='k', cmap = cm_bright)\n",
    "x_min, x_max = X_train[:, 0].min() - .5, X_train[:, 0].max() + .5\n",
    "y_min, y_max = X_train[:, 1].min() - .5, X_train[:, 1].max() + .5\n",
    "h = 0.02 # step in the mesh\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z_binary = Z>=0.5\n",
    "Z_binary = Z_binary.reshape(xx.shape)\n",
    "ax.contourf(xx, yy, Z_binary, cmap=cm_bright, alpha=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f28ce4-36d3-4ca7-a40d-6eff43addb71",
   "metadata": {},
   "source": [
    "__Confusion Matrices__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9180c728-4d1b-4755-bf0c-1f531ba8137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Comparing the predictions against the actual observations in y_test\n",
    "#Complete the line below to produce a confusion matrix\n",
    "#Hint: remember you can add a tab in Jupyter Lab to \"Show Contextual Help\"\n",
    "cm = \n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204fe34c-547c-4627-8e0c-d379091d24db",
   "metadata": {},
   "source": [
    "Use a `seaborn` heatmap to visualise the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576d6db2-994f-4bbc-99de-1b440fa5f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "# Insert code to calculate the accuracy, precision, recall and F1 score of the model.\n",
    "accuracy  = \n",
    "precision = \n",
    "recall    = \n",
    "f1_score  = \n",
    "stats_text = \"\\n\\nAccuracy={:0.2f}\\nPrecision={:0.2f}\\nRecall={:0.2f}\\nF1 Score={:0.2f}\".format(\n",
    "                accuracy,precision,recall,f1_score)\n",
    "sn.heatmap(cm, annot=True, cmap='Blues')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted' + stats_text)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26793f4b-2edd-4248-94b4-9c0edaa1911c",
   "metadata": {},
   "source": [
    "__Move to Practical8b.ipynb__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00f325a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
