{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f5acef6",
   "metadata": {},
   "source": [
    "Practical: $k$-Means Clustering\n",
    "==\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09fc3f4-3173-451a-91f5-5ff707e62d64",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> \n",
    "    \n",
    "Before we embark on this practical, I wanted to highlight the difference between *clustering* and *classification*. This practical is focused on a technique for **clustering** (we covered classification in the last block).\n",
    "\n",
    "In general, with clustering, we *don't know* what the *\"correct\"* clustering for a set of points is; indeed, there may not *be* a definitively \"correct\" clustering. In several of the examples below, we are using datasets (either artificially created, or loaded in) where the points do, in fact, belong to some class. This is simply a convenience to ensure that we have data where the algorithm will find some clusters. In the examples below, we can compare the cluster number (found by the algorithm) to the \"hidden\" actual class (that we didn't feed into the algorithm) to see how well the algorithm finds clusters. Usually you won't have this luxury... The whole point of the clustering algorithm is to expose a hidden underlying pattern. Normally, to assess the quality of the clustering, you have to fall back on metrics like in-cluster sum of squares. Even more important than these metrics, if you're *really* doing Exploratory Data Analysis, is to ask whether the clusters suggest anything to you about the data or give you a segmentation that's useful for you to work with.\n",
    "    \n",
    "</div>\n",
    "\n",
    "In this practical, we'll first look at a version of the $k$-means algorithm that we've written ourselves (part 1). You can look at this code to see how this works, and to see how it relates to the algorithm described in the videos. The idea here is to help you see how this algorithm could be implemented. In part 2, we'll show you how to use $k$-means from `scikit-learn`. In practice, this is how you will normally use $k$-means: you will use an established implementation that is known to be correct and to perform well. In parts 1 and 2, you will we working with an artifical dataset that has been constructed to help you explore the algorithm. In part 3, you will run the algorithm in a real (albeit small and controlled) dataset."
   ]
  },
  {
   "cell_type": "raw",
   "id": "8210faeb-5de9-438a-8b33-e04be04b45dc",
   "metadata": {},
   "source": [
    "### Before you start\n",
    "\n",
    "- Check that `MyKmeans.py` file is the same folder as this Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7401a8fa",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427fd283",
   "metadata": {},
   "source": [
    "PART 1 - Hard coded k-means\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746dcb63-8bc3-4d10-87ce-6dd068c88b57",
   "metadata": {},
   "source": [
    "### Implementing $k$-means\n",
    "- In this first part of the practical we're going to implement $k$-means from scratch based on what we learnt in the lecture.\n",
    "- The file `MyKmeans.py` contains code that implements $k$-means clustering.\n",
    "- Open the file and go through the function making sure you understand what every step does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97869f9f",
   "metadata": {},
   "source": [
    "Let's first simulate some data to use in our clustering and plot them using a scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a66f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(2) #setting a seed ensures that the clustering is reproducible\n",
    "data=np.random.normal(size=250*2).reshape(250,2)\n",
    "data[0:124,0]=data[0:124,0]+3\n",
    "data[0:124,1]=data[0:124,1]-4\n",
    "\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.scatter(data[:,0],data[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607f99e1",
   "metadata": {},
   "source": [
    "Now let's run `MyKmeans()` on this dataset and see if we identify the two clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685c5cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyKmeans import MyKmeans #this runs the contents of the file MyKeans.py that you examined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b734f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_df=pd.DataFrame(data)\n",
    "MyRes2 = MyKmeans(df=data_df,n_cluster=2, c_initial=range(2))\n",
    "print(MyRes2)\n",
    "plt.scatter(MyRes2.iloc[:,0],MyRes2.iloc[:,1], c=MyRes2.iloc[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4ab80e",
   "metadata": {},
   "source": [
    "From visual inspection it looks like $k$-means has done a pretty good job in separating the data into clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f736dd3a",
   "metadata": {},
   "source": [
    "Use `crosstab()` from Pandas to compare the clusters' allocation with the true clusters.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>REMEMBER: </b> When you're doing this for real, you won't know what the \"true clusters\" are, or whether there even is some underlying class that these features correspond to! </div> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2868718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "true=list([0]*125+[1]*125) #construct a list with \"true\" cluster number\n",
    "pd.crosstab(MyRes2.cluster,true, colnames=[\"True\"], rownames=[\"kmeans\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68526061",
   "metadata": {},
   "source": [
    "Has it grouped all points correctly?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c816b6",
   "metadata": {},
   "source": [
    "Run the above for different numbers of clusters by adjusing `n_cluster` and `c_initial` and see how the clusters change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6219e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bc2ff4-c68c-4910-9591-50718ffde4ff",
   "metadata": {},
   "source": [
    "We've seen in the lecture that $k$-means tries to minimize the total within cluster sum of squares. The `calculateSS` function takes as intput the results of MyKmeans and calculates the total sum of squares within clusters and the total sum of squares between clusters.\n",
    "\n",
    "Go through the function and make sure you understand how it works and the differences between each quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c94e26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function calculateSS() \n",
    "#  Input: output from MyKmeans()\n",
    "#  Output: dataframe with Total within clusters, Between and Total Sum of Squares.\n",
    "\n",
    "def calculateSS(res_clusters):\n",
    "    \n",
    "    #Create a list with enough elements to store a number for each cluster referenced \n",
    "    Within_SS = [0]*int(res_clusters.iloc[:,res_clusters.shape[1]-1].max()+1)\n",
    "    \n",
    "    Total_SS = sum(res_clusters.iloc[:,0:res_clusters.shape[1]-1].apply(lambda x: sum((x-x.mean())**2), axis=1))\n",
    "    \n",
    "    for i in pd.unique(res_clusters.iloc[:,res_clusters.shape[1]-1]):\n",
    "        i=int(i)\n",
    "        df=res_clusters[res_clusters.cluster==i]\n",
    "        Within_SS[i] = sum(df.iloc[:,0:df.shape[1]-1].apply(lambda x: sum((x-x.mean())**2)))\n",
    "    \n",
    "    Total_Within_SS = sum(Within_SS)\n",
    "    \n",
    "    Between_SS = Total_SS-Total_Within_SS\n",
    "    \n",
    "    res=pd.DataFrame([[Total_Within_SS,Between_SS,Total_SS]])\n",
    "    res.columns=[\"Tot_Within\",\"Between\",\"Total\"]\n",
    "    \n",
    "    return(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec48152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateSS(MyRes2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2246425-32c6-4650-94e4-bec07e672a11",
   "metadata": {},
   "source": [
    "In our example, we know that there are 2 clusters by construction. If we didn't, how would we choose $k$?\n",
    "\n",
    "We'd need to run `MyKmeans` for various values of $k$ and choose the one after which the change in the total sum of squares within clusters becomes very small.\n",
    "\n",
    "Let's write a function that iteratively changes $k$ and each time calculates the total within clusters sum of squares using our `calculateSS()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dfc2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_k(max_k, data):\n",
    "    #create placeholder lists with the correct number of elements\n",
    "    res = [0] * (max_k+1)\n",
    "    MySS = [0] * (max_k+1)\n",
    "    for i in range(1,max_k+1):\n",
    "        print(\"Trying k means with \",i,\" clusters\")\n",
    "        res[i]=MyKmeans(df=data, n_cluster=i, c_initial=range(i))\n",
    "        MySS[i]=calculateSS(res_clusters=res[i])\n",
    "    return MySS[1:max_k+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dd6341",
   "metadata": {},
   "source": [
    "Run the function on `data_df` for up to 10 clusters and plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9006f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "k_res=choose_k(max_k=k, data=data_df)\n",
    "k_res=pd.concat(k_res, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eeaaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf860c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1,11),k_res['Tot_Within'], 'o')\n",
    "plt.ylabel(\"Total Within SS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783ff302",
   "metadata": {},
   "source": [
    "Looking at the above plot, would anything stop you choosing $k=3$? $k=2$ is probably better here, but it's not always clear exaclty where the 'elbow' is in plots like this.\n",
    "\n",
    "Run `MyKmeans()` for 3 and 4 clusters and plot the results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b890e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d693ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52b8494",
   "metadata": {},
   "source": [
    "PART 2 - Using kmeans from scikit-learn\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd04aad5",
   "metadata": {},
   "source": [
    "Most of the things we've done so far can easily be done using the `KMeans` function from `scikit-learn`. The [scikit-learn project](https://scikit-learn.org/) provides implementations of many useful machine learning algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4bfb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62c8442",
   "metadata": {},
   "source": [
    "Look at the help file for KMeans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93249746",
   "metadata": {},
   "outputs": [],
   "source": [
    "?KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec126a7",
   "metadata": {},
   "source": [
    "To run scikit-learn's KMeans() on our data for two clusters using the same initial centroids as we did before, run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03585cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=KMeans(n_clusters=2,init=data_df.iloc[0:2,:],max_iter=40, algorithm=\"lloyd\")\n",
    "Skmeans0=model.fit(data_df)\n",
    "Skmeans0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cefd43",
   "metadata": {},
   "source": [
    "You can see the which clusters the points are assigned to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fe4085",
   "metadata": {},
   "outputs": [],
   "source": [
    "Skmeans0.predict(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1f05e9",
   "metadata": {},
   "source": [
    "The total within sum of squares can be obtained as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9938c1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Skmeans0.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6a8fe7",
   "metadata": {},
   "source": [
    "Unfortunately, scikit-learn does not provide a way to directly access values for between-sum-of-squares and total-sum-of-squares.\n",
    "\n",
    "Positions of the centroids can be obtained as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a4bd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Skmeans0.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16abc33",
   "metadata": {},
   "source": [
    "You don't have to specify the initial centroids. You can let scikit learn find these. (Indeed, this is what it expects by default, which is why you may have received a warning above). For reproducible results, you can set the seed for random_state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a90393",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=KMeans(n_clusters=2,max_iter=40, random_state=777777, algorithm=\"lloyd\")\n",
    "Skmeans0=model.fit(data_df)\n",
    "Skmeans0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a10606",
   "metadata": {},
   "source": [
    "Compare the results with those obtained from our implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d8f840",
   "metadata": {},
   "source": [
    "`KMeans` runs the algorithm multiple times using different starting centroids (10, by default) and returns the one with the best results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c769164",
   "metadata": {},
   "source": [
    "It's good practice to try different starting centroids as the clustering results can depend on these. You can change the number of starting centroids that are used using the `n_init` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd003b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=KMeans(n_clusters=2, n_init=20, max_iter=40, random_state=777777, algorithm=\"lloyd\")\n",
    "Skmeans0=model.fit(data_df)\n",
    "Skmeans0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd669d50",
   "metadata": {},
   "source": [
    "Specifying `algorithm=\"lloyd\"` implements _k_-means almost identically to our written implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbe40d2",
   "metadata": {},
   "source": [
    "Alternative `KMeans()` implementations are available in scikit-learn that can be more robust than ours.\n",
    "\n",
    "Let's use scikit-learn's default option for this and slight alter our `choose_k` function to use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427d12d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Schoose_k(max_k, data):\n",
    "    #create placeholder lists with the correct number of elements\n",
    "    res = [0] * (max_k+1)\n",
    "    MySS = [0] * (max_k+1)\n",
    "    for i in range(1,max_k+1):\n",
    "        print(\"Trying k means with \",i,\" clusters\")\n",
    "        model=KMeans(n_clusters=i, n_init=20, max_iter=40, random_state=777777)\n",
    "        Skmeans0=model.fit(data_df)\n",
    "        res[i]=Skmeans0.inertia_\n",
    "    return res[1:max_k+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc9f24b",
   "metadata": {},
   "source": [
    "Run the above updated version using,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd384b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sk_res = Schoose_k(max_k=k, data=data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83059138",
   "metadata": {},
   "source": [
    "Let's plot the results along with ours and compare,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edefddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Blue:MyKmeans(), Orange:scikit-learn's KMeans()\")\n",
    "plt.plot(range(1,11),k_res['Tot_Within'], 'o')\n",
    "plt.ylabel(\"Total Within SS\")\n",
    "plt.plot(range(1,11),Sk_res, 'o', markersize=4)\n",
    "plt.ylabel(\"Total Within SS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effa96bf",
   "metadata": {},
   "source": [
    "Let's use $k=2$ again and run kmeans() to get the clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f264be56",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_res = KMeans(n_clusters=2, n_init=20, max_iter=40, random_state=777777).fit_predict(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5535493",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"MyKmeans clustering\")\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.scatter(MyRes2.iloc[:,0],MyRes2.iloc[:,1], c=MyRes2.iloc[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e58e32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Kmeans() clustering\")\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.scatter(data_df.iloc[:,0], data_df.iloc[:,1],c=S_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8956c0d",
   "metadata": {},
   "source": [
    "What do you notice in the above plots?\n",
    "\n",
    "Are the results obtained the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff32f486",
   "metadata": {},
   "source": [
    "PART 3 - KMeans() on the iris dataset\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afc3f16",
   "metadata": {},
   "source": [
    "The iris dataset is often used to illustrate clustering and classification. It's one of the datasets that's built into _R_ and it's also available in sklearn.datasets.\n",
    "\n",
    "The dataset contains the length and width of sepals and petals of different flowers of 3 different species: virginica, versicolor and setosa.\n",
    "\n",
    "In the plot below, the colour corresponds to the flower family of each observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d8d036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns           # the seaborn library provides a good function for making pair plots\n",
    "import sklearn.datasets as skd  # we use sklearn.datasets to get the iris dataset\n",
    "\n",
    "iris=skd.load_iris()\n",
    "iris_df=pd.DataFrame(iris.data)\n",
    "iris_df.columns=iris.feature_names\n",
    "iris_df['label']=[iris.target_names[t] for t in iris.target]\n",
    "\n",
    "palette=sns.color_palette(\"hls\", 3) # gives a red-green-blue colour palette\n",
    "sns.pairplot(iris_df, hue='label', palette=palette)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b059ed",
   "metadata": {},
   "source": [
    "As we see below, the dataset has 50 observations from each species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b798ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d70915",
   "metadata": {},
   "source": [
    "Looking at the pair plot above, could kmeans distinguish between the 3 species? Is there any one with which it could struggle?\n",
    "\n",
    "Let's try kmeans on the iris dataset using the true cluster number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c828a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_iris=KMeans(n_clusters=3, n_init=20, max_iter=100, random_state=777777).fit_predict(iris_df.iloc[:,0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1fe05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df['cluster_label']=cl_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0622a051",
   "metadata": {},
   "source": [
    "Plot the data and colour the points by the assigned clusters. How do the results compare to the true groups? **NOTE:** the colour-cluster combination will not align with those of the previous plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e9b6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f14fa7",
   "metadata": {},
   "source": [
    "Has _k_-means done a good job?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b737bec6",
   "metadata": {},
   "source": [
    "Compare the true class and the assigned clusters using [`crosstab` from Pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.crosstab.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4476235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636d4cdf",
   "metadata": {},
   "source": [
    "Now try scaling your data first before applying kmeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08b3a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "iris_scaled=scale(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f567f7f",
   "metadata": {},
   "source": [
    "Look at the help file of `scale` if you're not sure what it's doing.\n",
    "\n",
    "Run kmeans() on the scaled dataset, using the same seed, and store the results in cl_iris_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142f81f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cb49ac",
   "metadata": {},
   "source": [
    "Compare with the results from k_iris and the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c122f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer\n",
    "#comparing with unscaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb2713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer\n",
    "#comparing with the true labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47662101",
   "metadata": {},
   "source": [
    "Have the results changed? Has there been any improvement?\n",
    "\n",
    "_Normally_ you would expect scaling to improve the clustering. In fact, in this case, the clustering was already very successful, so it's possible that scaling will actually have a negative effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386f4a3f",
   "metadata": {},
   "source": [
    "Run `Schoose_k` for a series of k values. Would you have chosen $k=3$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172131cb",
   "metadata": {},
   "source": [
    "---\n",
    "## Acknowledgements and Reuse\n",
    "<p>\n",
    "<small>\n",
    "Python version by Adam Carter, EPCC, The University of Edinburgh, based on an R version previously created at EPCC, The University of Edinburgh.\n",
    "</small>\n",
    "</p>\n",
    "<p>\n",
    "<small>\n",
    "&copy; 2023 EPCC, The University of Edinburgh\n",
    "</small>\n",
    "</p>\n",
    "<p>\n",
    "<small>\n",
    "You are welcome to re-use this notebook and its contents under the terms of CC-BY-4.0\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4438a7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
